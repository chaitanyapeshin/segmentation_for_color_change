{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81EalhBWRDfu"
   },
   "source": [
    "# Downloading and Extracting Files from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1489,
     "status": "ok",
     "timestamp": 1692896379827,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "lqCo6piACF6t",
    "outputId": "12b73d0f-9cd8-46d2-cca7-d3244ea52a08"
   },
   "outputs": [],
   "source": [
    "! pip install -q kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122,
     "status": "ok",
     "timestamp": 1692896379953,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "HSbuEPYrO80o",
    "outputId": "0f7a1c29-89a5-4425-e5fb-287c841c48de"
   },
   "outputs": [],
   "source": [
    "! pwd\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1692896380196,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "GkUJXjX3Q9t1",
    "outputId": "2a0d999d-7b93-4381-a17a-39a012d187f2"
   },
   "outputs": [],
   "source": [
    "# uncomment if data needs to be downloaded and fed into the appropriate directory through kaggle\n",
    "# # make sure you have kaggle.json in your home directory (eg. in home/chaitanyapeshin)\n",
    "# ! mkdir .kaggle\n",
    "# ! cp ./kaggle.json ./.kaggle/\n",
    "# ! chmod 600 ./.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116,
     "status": "ok",
     "timestamp": 1692896380323,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "3gA_RNGvyYtR",
    "outputId": "1f23c5d8-4cb7-49a6-9eca-0a02920232c6"
   },
   "outputs": [],
   "source": [
    "# uncomment if started console in the home directory\n",
    "# %cd  Desktop/projects\n",
    "# ! mkdir 02_segmentation_for_color_change\n",
    "# %cd 02_segmentation_for_color_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1692896380327,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "Daga8nvkUXsc"
   },
   "outputs": [],
   "source": [
    "# uncomment if data needs to be downloaded and fed into the appropriate directory through kaggle\n",
    "# ! kaggle competitions download -c carvana-image-masking-challenge\n",
    "\n",
    "# ! mkdir carvana-image-masking-challenge-data\n",
    "# ! unzip carvana-image-masking-challenge.zip -d carvana-image-masking-challenge-data\n",
    "\n",
    "# %cd carvana-image-masking-challenge-data/\n",
    "# ! find . -name \"*.zip\" -exec unzip {} \\;\n",
    "# ! rm *.zip\n",
    "\n",
    "# %cd ..\n",
    "# ! rm *.zip\n",
    "\n",
    "# %cd carvana-image-masking-challenge-data/\n",
    "# ! mkdir raw_data\n",
    "# ! cp -r ./train ./train_hq ./test ./test_hq ./train_masks ./metadata.csv ./train_masks.csv ./raw_data\n",
    "# ! rm -r ./train ./train_hq ./test ./test_hq ./train_masks ./metadata.csv ./train_masks.csv\n",
    "\n",
    "# %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgTE3-WzRKDO"
   },
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1944,
     "status": "ok",
     "timestamp": 1692896382276,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "jms1tqbBQo4h",
    "outputId": "8897d168-735c-4225-863e-9691d5cd3c1f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import misc, ndimage\n",
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import transform\n",
    "from tqdm import tqdm\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "import keras.backend as KTF\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Configure GPU memory growth\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTqyHzgSRdIl"
   },
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1692896382319,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "5axurW5rRe4W"
   },
   "outputs": [],
   "source": [
    "PARENT_PATH = '../'\n",
    "DATA_PATH = os.path.join(PARENT_PATH, 'data')\n",
    "PROCESSED_DATA_PATH = os.path.join(DATA_PATH, 'processed')\n",
    "TRAIN_PATH = os.path.join(PROCESSED_DATA_PATH, 'train_small_3')\n",
    "# TEST_PATH = os.path.join(PROCESSED_DATA_PATH, 'test')\n",
    "TRAIN_MASKS_PATH = os.path.join(PROCESSED_DATA_PATH, 'train_masks_jpg_small_3')\n",
    "# TRAIN_MASKS_FIXED_PATH = os.path.join(DATA_PATH, 'fixed_masks/fix-HCK')\n",
    "TRAIN_MASKS_CSV_PATH = os.path.join(PROCESSED_DATA_PATH, 'train_masks_small_3.csv')\n",
    "SAMPLE_SUBMISSION_PATH = os.path.join(PARENT_PATH, 'sample_submission.csv')\n",
    "METADATA_PATH = os.path.join(PARENT_PATH, 'metadata.csv')\n",
    "# SUBMISSION_PATH = os.path.join(DATA_PATH, 'submissions')\n",
    "ASSETS_PATH = os.path.join(PARENT_PATH, 'assets')\n",
    "MODELS_PATH = os.path.join(ASSETS_PATH, 'models')\n",
    "TENSORBOARD_PATH = os.path.join(ASSETS_PATH, 'tensorboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1692896382392,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "-vh0tOP2Z2_R",
    "outputId": "3bbbf89d-77ef-417c-8fcb-157e40438847"
   },
   "outputs": [],
   "source": [
    "train_masks_df = pd.read_csv(TRAIN_MASKS_CSV_PATH)\n",
    "print('train_masks_df.shape', train_masks_df.shape)\n",
    "train_masks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 195,
     "status": "ok",
     "timestamp": 1692896382591,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "G1U8MvW1PhRb",
    "outputId": "b3caaa9f-194e-40bf-d31d-e83578883f35"
   },
   "outputs": [],
   "source": [
    "! pwd\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1692896382640,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "CCW2PsvAZ8F6"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "HEIGHT_ORIG = 1280\n",
    "WIDTH_ORIG = 1918\n",
    "CHANNELS_ORIG = 3\n",
    "\n",
    "HEIGHT = 1024\n",
    "WIDTH = 1024\n",
    "CHANNELS = 3\n",
    "new_shape = (HEIGHT, WIDTH, CHANNELS)\n",
    "mask_shape = (new_shape[0], new_shape[1], 1)\n",
    "\n",
    "def get_img_id(img_path):\n",
    "    img_id = img_path[:15]\n",
    "    return img_id\n",
    "\n",
    "img_ids = list(map(get_img_id, list(train_masks_df.img.values)))\n",
    "\n",
    "def load_image_disk(img_id, folder=TRAIN_PATH):\n",
    "    img = cv2.imread(os.path.join(folder, img_id + \".jpg\"))\n",
    "    return img\n",
    "\n",
    "def get_image(img_id):\n",
    "    return train_imgs[img_id]\n",
    "\n",
    "# Return mask as 1/0 binary img with single channel\n",
    "def load_mask_disk(img_id, folder=TRAIN_MASKS_PATH, filetype='jpg'):\n",
    "    mask_path = os.path.join(folder, \"{}_mask.{}\".format(img_id, filetype))\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if mask is None:\n",
    "        print(f\"Warning: Failed to read mask image for {img_id}\")\n",
    "        return None\n",
    "\n",
    "    if np.any(mask > 128):\n",
    "        # print(\"1\")\n",
    "        mask[mask > 128] = 1\n",
    "    # else:\n",
    "        # print(\"0\")\n",
    "\n",
    "    mask = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    return mask\n",
    "\n",
    "def get_mask(img_id):\n",
    "    return train_masks[img_id]\n",
    "\n",
    "# Helper functions to plot car, mask, masked_car\n",
    "def plot_image(img_id):\n",
    "    img = cv2.imread(os.path.join(TRAIN_PATH, img_id + \".jpg\"))\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot_mask(img_id, folder=TRAIN_MASKS_PATH, filetype='jpg', ax=None):\n",
    "    mask = cv2.imread(os.path.join(folder, \"{}_mask.{}\".format(img_id, filetype)))\n",
    "    if ax == None:\n",
    "        imgplot = plt.imshow(mask)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.imshow(mask)\n",
    "        ax.axis('off')\n",
    "\n",
    "def plot_masked_image(img_id, ax=None):\n",
    "    img = cv2.imread(os.path.join(TRAIN_PATH, img_id + \".jpg\"))\n",
    "    mask = cv2.imread(os.path.join(TRAIN_MASKS_PATH, img_id + \"_mask.jpg\"))\n",
    "    mask = mask[:,:,0:3]\n",
    "    mask[mask == 255] = 1\n",
    "    masked_img = img * mask\n",
    "    if ax == None:\n",
    "        imgplot = plt.imshow(masked_img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        ax.imshow(masked_img)\n",
    "        ax.axis('off')\n",
    "\n",
    "def gray2rgb(img):\n",
    "    img = np.squeeze(img)\n",
    "    w, h = img.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = img\n",
    "    ret[:, :, 1] = img\n",
    "    ret[:, :, 2] = img\n",
    "    return ret\n",
    "\n",
    "def resize_img(img, new_s = new_shape):\n",
    "    return transform.resize(img, new_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16272,
     "status": "ok",
     "timestamp": 1692896398916,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "JG5wsHUuaAhq",
    "outputId": "8670bfc6-a493-4080-a387-cf9f25f62b59"
   },
   "outputs": [],
   "source": [
    "# Read training images into memory\n",
    "train_imgs = {}\n",
    "for img_path in tqdm(os.listdir(TRAIN_PATH)):\n",
    "    img_id = get_img_id(img_path)\n",
    "    train_imgs[img_id] = cv2.resize(load_image_disk(img_id), (new_shape[0], new_shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3885,
     "status": "ok",
     "timestamp": 1692896402804,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "-OiK4IYQajbM",
    "outputId": "5c7bc0c0-3ceb-45ba-f696-88ceaea37607"
   },
   "outputs": [],
   "source": [
    "# Read training masks into memory\n",
    "train_masks = {}\n",
    "for img_path in tqdm(os.listdir(TRAIN_MASKS_PATH)):\n",
    "    img_id = get_img_id(img_path)\n",
    "    train_masks[img_id] = np.expand_dims(cv2.resize(load_mask_disk(img_id), (new_shape[0], new_shape[1])), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1692896402809,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "fy9M2CQtcRjW"
   },
   "outputs": [],
   "source": [
    "def randomHueSaturationValue(image, hue_shift_limit=(-180, 180),\n",
    "                             sat_shift_limit=(-255, 255),\n",
    "                             val_shift_limit=(-255, 255), u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        h, s, v = cv2.split(image)\n",
    "        hue_shift = np.random.uniform(hue_shift_limit[0], hue_shift_limit[1])\n",
    "        h = cv2.add(h, hue_shift)\n",
    "        sat_shift = np.random.uniform(sat_shift_limit[0], sat_shift_limit[1])\n",
    "        s = cv2.add(s, sat_shift)\n",
    "        val_shift = np.random.uniform(val_shift_limit[0], val_shift_limit[1])\n",
    "        v = cv2.add(v, val_shift)\n",
    "        image = cv2.merge((h, s, v))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "    return image\n",
    "\n",
    "def randomShiftScaleRotate(image, mask,\n",
    "                           shift_limit=(-0.0625, 0.0625),\n",
    "                           scale_limit=(-0.1, 0.1),\n",
    "                           rotate_limit=(-45, 45), aspect_limit=(0, 0),\n",
    "                           borderMode=cv2.BORDER_REFLECT_101, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        height, width, channel = image.shape\n",
    "\n",
    "        angle = np.random.uniform(rotate_limit[0], rotate_limit[1])  # degree\n",
    "        scale = np.random.uniform(1 + scale_limit[0], 1 + scale_limit[1])\n",
    "        aspect = np.random.uniform(1 + aspect_limit[0], 1 + aspect_limit[1])\n",
    "        sx = scale * aspect / (aspect ** 0.5)\n",
    "        sy = scale / (aspect ** 0.5)\n",
    "        dx = round(np.random.uniform(shift_limit[0], shift_limit[1]) * width)\n",
    "        dy = round(np.random.uniform(shift_limit[0], shift_limit[1]) * height)\n",
    "\n",
    "        cc = np.math.cos(angle / 180 * np.math.pi) * sx\n",
    "        ss = np.math.sin(angle / 180 * np.math.pi) * sy\n",
    "        rotate_matrix = np.array([[cc, -ss], [ss, cc]])\n",
    "\n",
    "        box0 = np.array([[0, 0], [width, 0], [width, height], [0, height], ])\n",
    "        box1 = box0 - np.array([width / 2, height / 2])\n",
    "        box1 = np.dot(box1, rotate_matrix.T) + np.array([width / 2 + dx, height / 2 + dy])\n",
    "\n",
    "        box0 = box0.astype(np.float32)\n",
    "        box1 = box1.astype(np.float32)\n",
    "        mat = cv2.getPerspectiveTransform(box0, box1)\n",
    "        image = cv2.warpPerspective(image, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                    borderValue=(0, 0, 0,))\n",
    "        mask = cv2.warpPerspective(mask, mat, (width, height), flags=cv2.INTER_LINEAR, borderMode=borderMode,\n",
    "                                   borderValue=(0, 0, 0,))\n",
    "        if len(mask.shape) == 2:\n",
    "            mask = np.expand_dims(mask, axis=2)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def randomHorizontalFlip(image, mask, u=0.5):\n",
    "    if np.random.random() < u:\n",
    "        image = cv2.flip(image, 1)\n",
    "        mask = cv2.flip(mask, 1)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Q3yyiasdjiF"
   },
   "source": [
    "# Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1692896402814,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "I7fPjPWOctFm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "def generate_training_batch(data, batch_size):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        batch_ids = np.random.choice(data,\n",
    "                                     size=batch_size,\n",
    "                                     replace=False)\n",
    "        for idx, img_id in enumerate(batch_ids):\n",
    "            x = get_image(img_id)\n",
    "            y = get_mask(img_id)\n",
    "            x, y = randomShiftScaleRotate(x, y,\n",
    "                                          shift_limit=(-0.0625, 0.0625),\n",
    "                                          scale_limit=(-0.1, 0.1),\n",
    "                                          rotate_limit=(-0, 0))\n",
    "#             x = randomHueSaturationValue(x,\n",
    "#                                hue_shift_limit=(-50, 50),\n",
    "#                                sat_shift_limit=(-5, 5),\n",
    "#                                val_shift_limit=(-15, 15))\n",
    "            X_batch.append(x)\n",
    "            Y_batch.append(y)\n",
    "        X = np.asarray(X_batch, dtype=np.float32)\n",
    "        Y = np.asarray(Y_batch, dtype=np.float32)\n",
    "        yield X, Y\n",
    "\n",
    "def generate_validation_batch(data, batch_size):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        Y_batch = []\n",
    "        batch_ids = np.random.choice(data,\n",
    "                                     size=batch_size,\n",
    "                                     replace=False)\n",
    "        for idx, img_id in enumerate(batch_ids):\n",
    "            x = get_image(img_id)\n",
    "            y = get_mask(img_id)\n",
    "            X_batch.append(x)\n",
    "            Y_batch.append(y)\n",
    "        X = np.asarray(X_batch, dtype=np.float32)\n",
    "        Y = np.asarray(Y_batch, dtype=np.float32)\n",
    "        yield X, Y\n",
    "\n",
    "def generate_validation_data_seq(data):\n",
    "    idx = 0\n",
    "    while True:\n",
    "        img_id = data[idx]\n",
    "        X = get_image(img_id)\n",
    "        Y = get_mask(img_id)\n",
    "        yield img_id, X, Y\n",
    "        idx  += 1\n",
    "        if idx >= len(data):\n",
    "            break\n",
    "\n",
    "# def get_model_memory_usage(batch_size, model):\n",
    "#     from keras import backend as K\n",
    "\n",
    "#     shapes_mem_count = 0\n",
    "#     for l in model.layers:\n",
    "#         single_layer_mem = 1\n",
    "#         for s in l.output_shape:\n",
    "#             if s is None:\n",
    "#                 continue\n",
    "#             single_layer_mem *= s\n",
    "#         shapes_mem_count += single_layer_mem\n",
    "\n",
    "#     trainable_count = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "#     non_trainable_count = int(np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n",
    "\n",
    "#     total_memory = 4*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "#     gbytes = round(total_memory / (1024 ** 3), 3)\n",
    "#     mbytes = round(total_memory / (1024 ** 2), 3)\n",
    "\n",
    "#     print('trainable_count', trainable_count, 'non_trainable_count', non_trainable_count, 'gbytes', gbytes, 'mbytes', mbytes)\n",
    "\n",
    "def get_model_memory_usage(batch_size, model):\n",
    "    shapes_mem_count = 0\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer.output_shape, list):\n",
    "            for output_shape in layer.output_shape:\n",
    "                single_layer_mem = 1\n",
    "                for s in output_shape:\n",
    "                    if s is None:\n",
    "                        continue\n",
    "                    single_layer_mem *= s\n",
    "                shapes_mem_count += single_layer_mem\n",
    "        else:\n",
    "            single_layer_mem = 1\n",
    "            for s in layer.output_shape:\n",
    "                if s is None:\n",
    "                    continue\n",
    "                single_layer_mem *= s\n",
    "            shapes_mem_count += single_layer_mem\n",
    "\n",
    "    # trainable_count = int(np.sum([K.count_params(p) for p in set(model.trainable_weights)]))\n",
    "    trainable_count = int(np.sum([K.count_params(p) for p in model.trainable_weights]))\n",
    "    # non_trainable_count = int(np.sum([K.count_params(p) for p in set(model.non_trainable_weights)]))\n",
    "    non_trainable_count = int(np.sum([K.count_params(p) for p in model.non_trainable_weights]))\n",
    "\n",
    "    total_memory = shapes_mem_count * batch_size * 4  # Assuming float32 data type\n",
    "    total_memory += (trainable_count + non_trainable_count) * 4  # Assuming float32 data type\n",
    "\n",
    "    return total_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "executionInfo": {
     "elapsed": 306,
     "status": "ok",
     "timestamp": 1692896403125,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "q_Ps7_Z5cyy5",
    "outputId": "961ecc28-edde-4690-d198-6ab38fa00808"
   },
   "outputs": [],
   "source": [
    "# Visualize impact of random shift scale rotate\n",
    "random_idx = np.random.randint(len(train_imgs.keys()))\n",
    "random_img_id = list(train_imgs.keys())[random_idx]\n",
    "plot_image(random_img_id)\n",
    "temp_img = get_image(random_img_id)\n",
    "mask = get_mask(random_img_id)\n",
    "temp_img, temp_mask = randomShiftScaleRotate(temp_img, mask,\n",
    "                              shift_limit=(-0.0625, 0.0625),\n",
    "                              scale_limit=(-0.1, 0.1),\n",
    "                              rotate_limit=(-0, 0))\n",
    "\n",
    "plt.imshow(temp_img * gray2rgb(temp_mask))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 719
    },
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1692896403540,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "mXGWkcwuczOf",
    "outputId": "90a1d600-420e-4690-d2f8-54f3f6620247"
   },
   "outputs": [],
   "source": [
    "# Visualize impact of random hue saturation\n",
    "# random_idx = np.random.randint(len(train_imgs.keys()))\n",
    "# random_img_id = list(train_imgs.keys())[random_idx]\n",
    "plot_image(random_img_id)\n",
    "temp_img = cv2.imread(os.path.join(TRAIN_PATH, '{}.jpg'.format(random_img_id)))\n",
    "temp_img = randomHueSaturationValue(temp_img,\n",
    "                               hue_shift_limit=(-50, 50),\n",
    "                               sat_shift_limit=(-5, 5),\n",
    "                               val_shift_limit=(-15, 15))\n",
    "plt.imshow(temp_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "executionInfo": {
     "elapsed": 506,
     "status": "ok",
     "timestamp": 1692896404056,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "K10yVng-dzkO",
    "outputId": "7c5409d4-5cfa-49a7-daa6-80a9d3846e5b"
   },
   "outputs": [],
   "source": [
    "def sharpen(img):\n",
    "    #face = misc.face(gray=True).astype(float)\n",
    "    blurred_f = ndimage.gaussian_filter(img, 3)\n",
    "    filter_blurred_f = ndimage.gaussian_filter(blurred_f, 1)\n",
    "    alpha = 30\n",
    "    sharpened = blurred_f + alpha * (blurred_f - filter_blurred_f)\n",
    "    return sharpened\n",
    "\n",
    "\n",
    "plt.imshow(sharpen(temp_img))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P71XYgpBd5bD"
   },
   "source": [
    "# Building Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1692896404061,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "3ynaK2QFd2X8"
   },
   "outputs": [],
   "source": [
    "def down(filters, input_):\n",
    "    down_ = Conv2D(filters, (3, 3), padding='same')(input_)\n",
    "    down_ = BatchNormalization(epsilon=1e-4)(down_)\n",
    "    down_ = Activation('relu')(down_)\n",
    "    down_ = Conv2D(filters, (3, 3), padding='same')(down_)\n",
    "    down_ = BatchNormalization(epsilon=1e-4)(down_)\n",
    "    down_res = Activation('relu')(down_)\n",
    "    down_pool = MaxPooling2D((2, 2), strides=(2, 2))(down_)\n",
    "    return down_pool, down_res\n",
    "\n",
    "def up(filters, input_, down_):\n",
    "    up_ = UpSampling2D((2, 2))(input_)\n",
    "    up_ = concatenate([down_, up_], axis=3)\n",
    "    up_ = Conv2D(filters, (3, 3), padding='same')(up_)\n",
    "    up_ = BatchNormalization(epsilon=1e-4)(up_)\n",
    "    up_ = Activation('relu')(up_)\n",
    "    up_ = Conv2D(filters, (3, 3), padding='same')(up_)\n",
    "    up_ = BatchNormalization(epsilon=1e-4)(up_)\n",
    "    up_ = Activation('relu')(up_)\n",
    "    up_ = Conv2D(filters, (3, 3), padding='same')(up_)\n",
    "    up_ = BatchNormalization(epsilon=1e-4)(up_)\n",
    "    up_ = Activation('relu')(up_)\n",
    "    return up_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1692896404067,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "x9HdrVemeBr-"
   },
   "outputs": [],
   "source": [
    "def get_unet_1024(input_shape=(HEIGHT, WIDTH, CHANNELS), num_classes=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        #down0b, down0b_res = down(8, inputs)\n",
    "        down0a, down0a_res = down(24, inputs)\n",
    "        down0, down0_res = down(64, down0a)\n",
    "        down1, down1_res = down(128, down0)\n",
    "        down2, down2_res = down(256, down1)\n",
    "        down3, down3_res = down(512, down2)\n",
    "        down4, down4_res = down(768, down3)\n",
    "\n",
    "        center = Conv2D(768, (3, 3), padding='same')(down4)\n",
    "        center = BatchNormalization(epsilon=1e-4)(center)\n",
    "        center = Activation('relu')(center)\n",
    "\n",
    "    # with tf.device('/gpu:1'):\n",
    "        center = Conv2D(768, (3, 3), padding='same')(center)\n",
    "        center = BatchNormalization(epsilon=1e-4)(center)\n",
    "        center = Activation('relu')(center)\n",
    "\n",
    "        up4 = up(768, center, down4_res)\n",
    "        up3 = up(512, up4, down3_res)\n",
    "        up2 = up(256, up3, down2_res)\n",
    "        up1 = up(128, up2, down1_res)\n",
    "        up0 = up(64, up1, down0_res)\n",
    "        up0a = up(24, up0, down0a_res)\n",
    "        #up0b = up(8, up0a, down0b_res)\n",
    "\n",
    "    classify = Conv2D(num_classes, (1, 1), activation='sigmoid', name='final_layer')(up0a)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1692896404084,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "9t2XdGs6eCTL"
   },
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1692896404100,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "Wc4K7SboeEDs"
   },
   "outputs": [],
   "source": [
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    # avoiding overflow\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "\n",
    "    # https://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits\n",
    "    loss = (1. - y_true) * logit_y_pred + (1. + (weight - 1.) * y_true) * \\\n",
    "    (K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_coef(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight * weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    return score\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    return 1. - weighted_dice_coef(y_true, y_pred, weight)\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd number\n",
    "    averaged_mask = K.pool2d(y_true, pool_size=(11, 11), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    border = K.cast(K.greater(averaged_mask, 0.01), 'float32') * K.cast(K.less(averaged_mask, 0.99), 'float32')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight += border * 2\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + weighted_dice_loss(y_true, y_pred, weight)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOb7gzv7eHl9"
   },
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1692896404124,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "VMeZ0d17eFkp"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1184,
     "status": "ok",
     "timestamp": 1692896405315,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "14ggAlnSeKf2",
    "outputId": "b133544e-cff3-49b3-c26b-6f92451f7f4d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training new model\n",
    "ts = str(int(time.time()))\n",
    "model_name = 'malhot'\n",
    "num_epochs = 4\n",
    "steps_per_epoch = int(len(img_ids) * 0.8/BATCH_SIZE)\n",
    "run_name = 'model={}-batch_size={}-num_epoch={}-steps_per_epoch={}-ts={}'.format(model_name,\n",
    "                                                                          BATCH_SIZE,\n",
    "                                                                          num_epochs,\n",
    "                                                                          steps_per_epoch,\n",
    "                                                                          ts)\n",
    "tensorboard_loc = os.path.join(TENSORBOARD_PATH, run_name)\n",
    "checkpoint_loc = os.path.join(MODELS_PATH, 'model-{}-weights.h5'.format(ts))\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                              patience=2,\n",
    "                              verbose=1,\n",
    "                              min_delta = 0.0001,\n",
    "                              mode='min',)\n",
    "\n",
    "modelCheckpoint = ModelCheckpoint(checkpoint_loc,\n",
    "                                  monitor = 'val_loss',\n",
    "                                  save_best_only = True,\n",
    "                                  mode = 'min',\n",
    "                                  verbose = 1,\n",
    "                                  save_weights_only = True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=tensorboard_loc, histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "callbacks_list = [modelCheckpoint, earlyStopping, tensorboard]\n",
    "\n",
    "model = get_unet_1024()\n",
    "model.compile(loss=bce_dice_loss, optimizer=Adam(lr=1e-4), metrics=[dice_coef])\n",
    "print(model.summary())\n",
    "get_model_memory_usage(BATCH_SIZE, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1692896439692,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "ChEQk6HTeRJh"
   },
   "outputs": [],
   "source": [
    "# # Re-training old model\n",
    "# ts = str(int(time.time()))\n",
    "# model_name = 'malhot'\n",
    "# num_epochs = 300\n",
    "# steps_per_epoch = 101\n",
    "# run_name = 'model={}-batch_size={}-num_epoch={}-steps_per_epoch={}-ts={}'.format(model_name,\n",
    "#                                                                           BATCH_SIZE,\n",
    "#                                                                           num_epochs,\n",
    "#                                                                           steps_per_epoch,\n",
    "#                                                                           ts)\n",
    "# tensorboard_loc = os.path.join(TENSORBOARD_PATH, run_name)\n",
    "# checkpoint_loc = os.path.join(MODELS_PATH, 'model-{}-weights.h5'.format(ts))\n",
    "\n",
    "# modelCheckpoint = ModelCheckpoint(checkpoint_loc,\n",
    "#                                   monitor = 'val_loss',\n",
    "#                                   save_best_only = True,\n",
    "#                                   mode = 'min',\n",
    "#                                   verbose = 1,\n",
    "#                                   save_weights_only = True)\n",
    "\n",
    "# tensorboard = TensorBoard(log_dir=tensorboard_loc, histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "# callbacks_list = [modelCheckpoint, tensorboard]\n",
    "\n",
    "# model = get_unet_1024()\n",
    "# model.load_weights(os.path.join(MODELS_PATH, 'model-1506108708-weights.h5'))\n",
    "# model.compile(loss=weighted_bce_dice_loss, optimizer=AdamAccumulate(lr=1e-5, accum_iters=5), metrics=[dice_coef])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1692896440853,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "9Ze3O7CveRke"
   },
   "outputs": [],
   "source": [
    "train_ids, validation_ids = model_selection.train_test_split(img_ids, random_state=42, test_size=0.20)\n",
    "train_generator = generate_training_batch(train_ids, BATCH_SIZE)\n",
    "valid_generator = generate_validation_batch(validation_ids, BATCH_SIZE)\n",
    "VALIDATION_STEPS = int(len(validation_ids) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 18013,
     "status": "error",
     "timestamp": 1692896460630,
     "user": {
      "displayName": "Chaitanya Peshin",
      "userId": "13579483866386107857"
     },
     "user_tz": -330
    },
    "id": "xLhknUz-eT0M",
    "outputId": "eabe57e1-efea-4add-e4ca-b696e3911658",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Starting run {}'.format(run_name))\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch = steps_per_epoch,\n",
    "        epochs = num_epochs,\n",
    "        callbacks = callbacks_list,\n",
    "        verbose = 1,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = VALIDATION_STEPS)\n",
    "\n",
    "model_path = os.path.join(MODELS_PATH, 'model-{}.h5'.format(ts))\n",
    "history_path = os.path.join(MODELS_PATH, 'model-{}.history'.format(ts))\n",
    "model.save(model_path)\n",
    "pickle.dump(history.history, open(history_path, \"wb\"))\n",
    "print('Saved model at {}'.format(model_path))\n",
    "print('Saved model history at {}'.format(history_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear all gpu memory (due to an error in the previous train run)\n",
    "# doesn't work on sessions on google colab hosted using a local runtime through jupyter\n",
    "# unfortunately seems to be useless in this case for me :(\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Close plots and figures\n",
    "plt.close('all')\n",
    "\n",
    "# # Delete variables if needed\n",
    "# del variable_name\n",
    "\n",
    "# Clear GPU memory\n",
    "def clear_gpu_memory():\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "# Call the function to free GPU memory\n",
    "clear_gpu_memory()\n",
    "\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing package to clear up GPU memory when running on local\n",
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to clear up GPU memory when running on local\n",
    "# unfortunately, this kills the kernel and also, is useless :(\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzAAQkB6ebcU"
   },
   "outputs": [],
   "source": [
    "model = get_unet_1024()\n",
    "model.load_weights(os.path.join(MODELS_PATH, 'model-1506223599-weights.h5'))\n",
    "model.compile(loss=bce_dice_loss, optimizer=Adam(1e-5), metrics=[dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETuNFLPcebxw"
   },
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(MODELS_PATH, 'model-1506223599.h5'), custom_objects={'weighted_bce_dice_loss': weighted_bce_dice_loss,\n",
    "                                                                                    'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALkU0WGIec0m"
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(valid_generator, VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvm_2O1Tefdl"
   },
   "source": [
    "# Error Analysis on Val Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seoAtBpEeieW"
   },
   "outputs": [],
   "source": [
    "validation_dices = []\n",
    "for img_id, X, Y in generate_validation_data_seq(validation_ids):\n",
    "    error = model.evaluate(np.expand_dims(X, axis=0), np.expand_dims(Y, axis=0), verbose=0)\n",
    "    validation_dices.append((img_id, error[0], error[1]))\n",
    "\n",
    "val_eval_df = pd.DataFrame.from_records(validation_dices, columns=['img_id', 'val_loss', 'dice_coef'])\n",
    "val_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmPKkvjQelHm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNCttvHXrX03cl+NxgME9Y/",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
